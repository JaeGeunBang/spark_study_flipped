{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sc = org.apache.spark.sql.SparkSession@44c82c5c\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2.4.3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "val sc = SparkSession.builder().getOrCreate()\n",
    "sc.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: timestamp (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: double (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df = [InvoiceNo: string, StockCode: string ... 6 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[InvoiceNo: string, StockCode: string ... 6 more fields]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = sc.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\")\n",
    "            .load(\"./by-day/2010-12-10.csv\")\n",
    "df.printSchema()\n",
    "df.createOrReplaceTempView(\"dfTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   538172|    21562|HAWAIIAN GRASS SK...|      12|2010-12-10 09:33:00|     1.25|   15805.0|United Kingdom|\n",
      "|   538172|    79321|       CHILLI LIGHTS|       8|2010-12-10 09:33:00|     4.95|   15805.0|United Kingdom|\n",
      "|   538172|    22041|\"RECORD FRAME 7\"\"...|      12|2010-12-10 09:33:00|     2.55|   15805.0|United Kingdom|\n",
      "|   538172|   84558A|3D DOG PICTURE PL...|      12|2010-12-10 09:33:00|     2.95|   15805.0|United Kingdom|\n",
      "|   538172|    22952|60 CAKE CASES VIN...|      24|2010-12-10 09:33:00|     0.55|   15805.0|United Kingdom|\n",
      "|   538172|    22910|PAPER CHAIN KIT V...|      24|2010-12-10 09:33:00|     2.95|   15805.0|United Kingdom|\n",
      "|   538172|    21098|CHRISTMAS TOILET ...|      24|2010-12-10 09:33:00|     1.25|   15805.0|United Kingdom|\n",
      "|   538172|    84212|\"ASSORTED FLOWER ...|      24|2010-12-10 09:33:00|     0.65|   15805.0|United Kingdom|\n",
      "|   538172|    21870|I CAN ONLY PLEASE...|      12|2010-12-10 09:33:00|     1.25|   15805.0|United Kingdom|\n",
      "|   538172|    22834|HAND WARMER BABUS...|      36|2010-12-10 09:33:00|      2.1|   15805.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 스파크 데이터 타입으로 변환하기\n",
    "\n",
    "프로그래밍 언어의 고유 데이터 타입을 lit 함수를 사용해 스파크 데이터 타입으로 변환함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+\n",
      "|  5|five|5.0|\n",
      "+---+----+---+\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "+---+----+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.lit\n",
    "\n",
    "df.select(lit(5), lit(\"five\"), lit(5.0)).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 불리언 데이터 타입 다루기\n",
    "\n",
    "불리언은 모든 필터링 작업의 기반이므로 필수적으로 알아야 함. <br>\n",
    "and, or, true, false로 구성됨. <br>\n",
    "불리언 구문을 사용해 true 또는 false로 평가되는 논리 문법을 만들고, 논리 문법은 데이터 로우를 필터링할 때 필요조건의 일치(true)와 불일치(false)를 판별하는데 사용됨. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------------------------+\n",
      "|InvoiceNo|Description                       |\n",
      "+---------+----------------------------------+\n",
      "|538174   |SET OF 72 RETROSPOT PAPER  DOILIES|\n",
      "|538174   |PACK OF 72 RETROSPOT CAKE CASES   |\n",
      "|538174   |WOODLAND DESIGN  COTTON TOTE BAG  |\n",
      "|538174   |BIG DOUGHNUT FRIDGE MAGNETS       |\n",
      "|538174   |RECYCLED PENCIL WITH RABBIT ERASER|\n",
      "+---------+----------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------+----------------------------------+\n",
      "|InvoiceNo|Description                       |\n",
      "+---------+----------------------------------+\n",
      "|538174   |SET OF 72 RETROSPOT PAPER  DOILIES|\n",
      "|538174   |PACK OF 72 RETROSPOT CAKE CASES   |\n",
      "|538174   |WOODLAND DESIGN  COTTON TOTE BAG  |\n",
      "|538174   |BIG DOUGHNUT FRIDGE MAGNETS       |\n",
      "|538174   |RECYCLED PENCIL WITH RABBIT ERASER|\n",
      "+---------+----------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.col\n",
    "\n",
    "df.where(col(\"InvoiceNo\").equalTo(538174))\n",
    "    .select(\"InvoiceNo\", \"Description\")\n",
    "    .show(5, false)\n",
    "\n",
    "// equalTo는 스칼라에서 === 와 동일하다.\n",
    "// ==는 reference 비교, ===은 value 비교\n",
    "df.where(col(\"InvoiceNo\") === (538174))\n",
    "    .select(\"InvoiceNo\", \"Description\")\n",
    "    .show(5, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+----------------------------------+--------+-------------------+---------+----------+-------+\n",
      "|InvoiceNo|StockCode|Description                       |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country|\n",
      "+---------+---------+----------------------------------+--------+-------------------+---------+----------+-------+\n",
      "|538174   |21210    |SET OF 72 RETROSPOT PAPER  DOILIES|12      |2010-12-10 09:35:00|1.45     |12471.0   |Germany|\n",
      "|538174   |21212    |PACK OF 72 RETROSPOT CAKE CASES   |24      |2010-12-10 09:35:00|0.55     |12471.0   |Germany|\n",
      "|538174   |21578    |WOODLAND DESIGN  COTTON TOTE BAG  |24      |2010-12-10 09:35:00|2.25     |12471.0   |Germany|\n",
      "|538174   |21700    |BIG DOUGHNUT FRIDGE MAGNETS       |72      |2010-12-10 09:35:00|0.85     |12471.0   |Germany|\n",
      "|538174   |16235    |RECYCLED PENCIL WITH RABBIT ERASER|60      |2010-12-10 09:35:00|0.21     |12471.0   |Germany|\n",
      "+---------+---------+----------------------------------+--------+-------------------+---------+----------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------+---------+-------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description                    |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+-------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "|538172   |21562    |HAWAIIAN GRASS SKIRT           |12      |2010-12-10 09:33:00|1.25     |15805.0   |United Kingdom|\n",
      "|538172   |79321    |CHILLI LIGHTS                  |8       |2010-12-10 09:33:00|4.95     |15805.0   |United Kingdom|\n",
      "|538172   |22041    |\"RECORD FRAME 7\"\" SINGLE SIZE \"|12      |2010-12-10 09:33:00|2.55     |15805.0   |United Kingdom|\n",
      "|538172   |84558A   |3D DOG PICTURE PLAYING CARDS   |12      |2010-12-10 09:33:00|2.95     |15805.0   |United Kingdom|\n",
      "|538172   |22952    |60 CAKE CASES VINTAGE CHRISTMAS|24      |2010-12-10 09:33:00|0.55     |15805.0   |United Kingdom|\n",
      "+---------+---------+-------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// 가장 명확한 방법은 문자열 표현식에 조건절을 명시하는 것.\n",
    "df.where(\"InvoiceNo = 538174\").show(5, false)\n",
    "df.where(\"InvoiceNo <> 538174\").show(5, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and, or 메서드는 사용해서 불리언 표현식을 여러 부분으로 지정할 수 있다. <br>\n",
    "불리언 표현식을 사용하는 경우 항상 모든 표현식을 and 메서드로 묶어 차례대로 필터를 적용함. <br>\n",
    "<br>\n",
    "스파크는 내부적으로 and 구문을 필터 사이에 추가해 모든 필터를 하나의 문장으로 변환함. functional lan 이기 떄문 <br>\n",
    " - 그후 동시에 모든 필터를 처리한다.\n",
    "차례로 조건을 나열하면 이해하기 쉽고 읽기도 편해짐.\n",
    " - 반면 or 구문을 사용할 때는 반드시 동일한 구문에 조건을 정의해야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|   Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "|   538177|      DOT|DOTCOM POSTAGE|       1|2010-12-10 09:51:00|   847.42|      null|United Kingdom|\n",
      "|   538349|      DOT|DOTCOM POSTAGE|       1|2010-12-10 14:59:00|   907.47|      null|United Kingdom|\n",
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "priceFilter = (UnitPrice > 600)\n",
       "descripFilter = contains(Description, POSTAGE)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "contains(Description, POSTAGE)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// or 구문을 적용하기 위해 priceFilter, descripFilter를 만들어 or 메서드를 사용함.\n",
    "val priceFilter = col(\"UnitPrice\") > 600\n",
    "val descripFilter = col(\"Description\").contains(\"POSTAGE\")\n",
    "df.where(col(\"StockCode\").isin(\"DOT\")).where(priceFilter.or(descripFilter)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|unitPrice|isExpensive|\n",
      "+---------+-----------+\n",
      "|   847.42|       true|\n",
      "|   907.47|       true|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DOTCodeFilter = (StockCode = DOT)\n",
       "priceFilter = (UnitPrice > 600)\n",
       "descripFilter = contains(Description, POSTAGE)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "contains(Description, POSTAGE)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 불리언 표현식을 필터링 조건에만 사용하는 것이 아니며, 아래와 같이 사용할수 있다.\n",
    "val DOTCodeFilter = col(\"StockCode\") === \"DOT\"\n",
    "val priceFilter = col(\"UnitPrice\") > 600\n",
    "val descripFilter = col(\"Description\").contains(\"POSTAGE\")\n",
    "df.withColumn(\"isExpensive\", DOTCodeFilter.and(priceFilter.or(descripFilter)))\n",
    "    .where(\"isExpensive\").select(\"unitPrice\", \"isExpensive\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+\n",
      "|   Description|UnitPrice|\n",
      "+--------------+---------+\n",
      "|DOTCOM POSTAGE|   847.42|\n",
      "|DOTCOM POSTAGE|   907.47|\n",
      "+--------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// 위와 같이 필터를 반드시 표현식으로 정의할 필요는 없다.\n",
    "import org.apache.spark.sql.functions.{expr, not, col}\n",
    "\n",
    "df.withColumn(\"isExpensive\", not(col(\"UnitPrice\").leq(250)))\n",
    "    .filter(\"isExpensive\")\n",
    "    .select(\"Description\", \"UnitPrice\").show(5)\n",
    "\n",
    "// 아래 코드는 SQL에 익숙한 사람들이 사용하기 좋음.\n",
    "// SQL을 사용한다고 해서 성능 저하가 발생하지 않는다.\n",
    "df.withColumn(\"isExpensive\", expr(\"NOT UnitPrice <= 250\"))\n",
    "    .filter(\"isExpensive\")\n",
    "    .select(\"Description\", \"UnitPrice\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|InvoiceNo|StockCode|Description|Quantity|InvoiceDate|UnitPrice|CustomerID|Country|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(col(\"Description\").eqNullSafe(\"Country\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 수치형 데이터 타입 다루기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|CustomerId|realQuantity|\n",
      "+----------+------------+\n",
      "|   15805.0|       230.0|\n",
      "|   15805.0|     1573.16|\n",
      "+----------+------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+----------+------------+\n",
      "|CustomerId|realQuantity|\n",
      "+----------+------------+\n",
      "|   15805.0|       230.0|\n",
      "|   15805.0|     1573.16|\n",
      "+----------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fabricatedQuantity = (POWER((Quantity * UnitPrice), 2.0) + 5)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(POWER((Quantity * UnitPrice), 2.0) + 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 간단한 수량을 더하는 작업\n",
    "import org.apache.spark.sql.functions.{expr, pow}\n",
    "\n",
    "val fabricatedQuantity = pow(col(\"Quantity\") * col(\"UnitPrice\"), 2) + 5\n",
    "df.select(expr(\"CustomerId\"), fabricatedQuantity.alias(\"realQuantity\")).show(2)\n",
    "\n",
    "// SQL 표현\n",
    "df.selectExpr(\"CustomerId\", \"POWER((Quantity * UnitPrice), 2.0) + 5 as realQuantity\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|rounded|UnitPrice|\n",
      "+-------+---------+\n",
      "|    1.3|     1.25|\n",
      "|    5.0|     4.95|\n",
      "|    2.6|     2.55|\n",
      "|    3.0|     2.95|\n",
      "|    0.6|     0.55|\n",
      "+-------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// 반올림. 때로는 소수점 자리를 없애기 위해 Integer 데이터 타입으로 형변환하기도 함.\n",
    "// 내림은 bround 함수를 사용함.\n",
    "import org.apache.spark.sql.functions.{round, bround}\n",
    "df.select(round(col(\"UnitPrice\"), 1).alias(\"rounded\"), col(\"UnitPrice\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+\n",
      "|round(2.5, 0)|bround(2.5, 0)|\n",
      "+-------------+--------------+\n",
      "|          3.0|           2.0|\n",
      "|          3.0|           2.0|\n",
      "+-------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// 반올림, 버림의 예시\n",
    "import org.apache.spark.sql.functions.lit\n",
    "\n",
    "df.select(round(lit(\"2.5\")), bround(lit(\"2.5\"))).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|corr(Quantity, UnitPrice)|\n",
      "+-------------------------+\n",
      "|     -0.02802551979854...|\n",
      "+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// 두 컬럼 사이의 상관관계 계산\n",
    "import org.apache.spark.sql.functions.{corr}\n",
    "\n",
    "df.stat.corr(\"Quantity\", \"UnitPrice\")\n",
    "df.select(corr(\"Quantity\", \"UnitPrice\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "|summary|        InvoiceNo|         StockCode|          Quantity|         UnitPrice|\n",
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "|  count|             2758|              2758|              2758|              2758|\n",
      "|   mean|538266.0758928572|27964.272652726526| 7.359318346627991| 4.650130529369104|\n",
      "| stddev|76.38281478503671| 17614.08058257242|19.786335248719404|24.187828632489182|\n",
      "|    min|           538172|             10002|              -145|               0.0|\n",
      "|    max|          C538362|              POST|               288|            907.47|\n",
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// 하나 이상의 컬럼에 대한 요약 통계를 계산하는 작업\n",
    "// 관련 컬럼에 대해 집계, 평균, 표준편차, 최솟값, 최대값 제공\n",
    "df.select(\"InvoiceNo\", \"StockCode\", \"Quantity\", \"UnitPrice\").describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "colName = UnitPrice\n",
       "quantileProbs = Array(0.5)\n",
       "relError = 0.05\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Array(2.51)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// statFunctions 패키지는 다양한 통계 함수를 제공한다.\n",
    "val colName = \"UnitPrice\"\n",
    "val quantileProbs = Array(0.5)\n",
    "val relError = 0.05\n",
    "\n",
    "// approxQuantile을 통해 데이터의 백분위수를 정확하게 계산하거나 근사치를 계산할 수 있음.\n",
    "df.stat.approxQuantile(colName, quantileProbs, relError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---+---+---+----+----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "|StockCode_Quantity| -1|-11|-12|-144|-145|-15|-18| -2|-20|-21|-24|-28| -3|-30|-36| -4|-47|-48| -6|-96|  1| 10|100|104|106|108| 11|113|115| 12|120|128| 13| 14|144| 15| 16| 17| 18| 19|192|  2| 20| 21|216| 22| 23| 24|240| 25| 26|267| 27|272|288| 29|  3| 30| 31| 32| 33| 35| 36| 38|  4| 40| 45| 47| 48|  5| 50|  6| 60| 64| 65| 68|  7| 70| 72| 75|  8| 80| 82| 84|  9| 96|\n",
      "+------------------+---+---+---+----+----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "|             22578|  0|  0|  0|   0|   0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|             21327|  0|  0|  0|   0|   0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|             22064|  0|  0|  0|   0|   0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|             21080|  0|  0|  0|   0|   0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|             22219|  0|  0|  0|   0|   0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  2|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|             37447|  0|  0|  0|   0|   0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|             21908|  0|  0|  0|   0|   0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|             22818|  0|  0|  0|   0|   0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  2|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|             22285|  0|  0|  0|   0|   0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|           15056BL|  0|  0|  0|   0|   0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  2|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  2|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|             72817|  0|  0|  0|   0|   0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|             22988|  0|  0|  1|   0|   0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  2|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  2|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|\n",
      "|             22274|  0|  0|  0|   0|   0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  2|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|            72351B|  0|  0|  0|   0|   0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|\n",
      "|             20750|  0|  0|  0|   0|   0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|             21703|  0|  0|  0|   0|   0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|             22899|  0|  0|  0|   0|   0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|             22379|  0|  0|  0|   0|   0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  2|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|             22422|  0|  0|  0|   0|   0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|             22769|  0|  0|  0|   0|   0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "+------------------+---+---+---+----+----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// crosstab을 통해 교차로나 자주 사용하는 항목 쌍을 확인하는 용도의 메서드\n",
    "// pivot?\n",
    "df.stat.crosstab(\"StockCode\", \"Quantity\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|monotonically_increasing_id()|\n",
      "+-----------------------------+\n",
      "|                            0|\n",
      "|                            1|\n",
      "|                            2|\n",
      "|                            3|\n",
      "|                            4|\n",
      "+-----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// monotonically_increasing_id를 통해 모든 로우에 고유 ID 값을 추가할 수 있음.\n",
    "import org.apache.spark.sql.functions.monotonically_increasing_id\n",
    "df.select(monotonically_increasing_id()).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 문자열 데이터 타입 다루기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+\n",
      "|initcap(Description)           |\n",
      "+-------------------------------+\n",
      "|Hawaiian Grass Skirt           |\n",
      "|Chilli Lights                  |\n",
      "|\"record Frame 7\"\" Single Size \"|\n",
      "|3d Dog Picture Playing Cards   |\n",
      "|60 Cake Cases Vintage Christmas|\n",
      "+-------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// initcap은 주어진 문자열에서 공백으로 나누는 모든 단어의 첫 글자를 대문자로 변경함.\n",
    "import org.apache.spark.sql.functions.{initcap}\n",
    "\n",
    "df.select(initcap(col(\"Description\"))).show(5, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------------+\n",
      "|         Description|  lower(Description)|upper(lower(Description))|\n",
      "+--------------------+--------------------+-------------------------+\n",
      "|HAWAIIAN GRASS SK...|hawaiian grass sk...|     HAWAIIAN GRASS SK...|\n",
      "|       CHILLI LIGHTS|       chilli lights|            CHILLI LIGHTS|\n",
      "|\"RECORD FRAME 7\"\"...|\"record frame 7\"\"...|     \"RECORD FRAME 7\"\"...|\n",
      "|3D DOG PICTURE PL...|3d dog picture pl...|     3D DOG PICTURE PL...|\n",
      "|60 CAKE CASES VIN...|60 cake cases vin...|     60 CAKE CASES VIN...|\n",
      "+--------------------+--------------------+-------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// 소문자로 변경 lower, 대문자로 변경 upper\n",
    "import org.apache.spark.sql.functions.{lower, upper}\n",
    "\n",
    "df.select(col(\"Description\"), \n",
    "         lower(col(\"Description\")),\n",
    "         upper(lower(col(\"Description\")))).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-----+---+----------+\n",
      "|   ltrim|   rtrim| trim| lp|        rp|\n",
      "+--------+--------+-----+---+----------+\n",
      "|HELLO   |   HELLO|HELLO|HEL|HELLO     |\n",
      "|HELLO   |   HELLO|HELLO|HEL|HELLO     |\n",
      "|HELLO   |   HELLO|HELLO|HEL|HELLO     |\n",
      "|HELLO   |   HELLO|HELLO|HEL|HELLO     |\n",
      "|HELLO   |   HELLO|HELLO|HEL|HELLO     |\n",
      "+--------+--------+-----+---+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// 공백 제거 함수들\n",
    "// lpad, rpad는 문자열의 길이보다 작은 숫자를 넘기면 문자열의 오른쪽부터 제거됨.\n",
    "import org.apache.spark.sql.functions.{lit, ltrim, rtrim, rpad, lpad, trim}\n",
    "\n",
    "df.select(\n",
    "    ltrim(lit(\"   HELLO   \")).as(\"ltrim\"),\n",
    "    rtrim(lit(\"   HELLO   \")).as(\"rtrim\"),\n",
    "    trim(lit(\"   HELLO   \")).as(\"trim\"),\n",
    "    lpad(lit(\"HELLO\"), 3, \" \").as(\"lp\"),\n",
    "    rpad(lit(\"HELLO\"), 10, \" \").as(\"rp\")\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+-----------------------------------+\n",
      "|color_clean                        |Description                        |\n",
      "+-----------------------------------+-----------------------------------+\n",
      "|HAWAIIAN GRASS SKIRT               |HAWAIIAN GRASS SKIRT               |\n",
      "|CHILLI LIGHTS                      |CHILLI LIGHTS                      |\n",
      "|\"RECORD FRAME 7\"\" SINGLE SIZE \"    |\"RECORD FRAME 7\"\" SINGLE SIZE \"    |\n",
      "|3D DOG PICTURE PLAYING CARDS       |3D DOG PICTURE PLAYING CARDS       |\n",
      "|60 CAKE CASES VINTAGE CHRISTMAS    |60 CAKE CASES VINTAGE CHRISTMAS    |\n",
      "|PAPER CHAIN KIT VINTAGE CHRISTMAS  |PAPER CHAIN KIT VINTAGE CHRISTMAS  |\n",
      "|CHRISTMAS TOILET ROLL              |CHRISTMAS TOILET ROLL              |\n",
      "|\"ASSORTED FLOWER COLOUR \"\"LEIS\"\"\"  |\"ASSORTED FLOWER COLOUR \"\"LEIS\"\"\"  |\n",
      "|I CAN ONLY PLEASE ONE PERSON MUG   |I CAN ONLY PLEASE ONE PERSON MUG   |\n",
      "|HAND WARMER BABUSHKA DESIGN        |HAND WARMER BABUSHKA DESIGN        |\n",
      "|BLUE HARMONICA IN BOX              |BLUE HARMONICA IN BOX              |\n",
      "|null                               |null                               |\n",
      "|SET OF 72 RETROSPOT PAPER  DOILIES |SET OF 72 RETROSPOT PAPER  DOILIES |\n",
      "|PACK OF 72 RETROSPOT CAKE CASES    |PACK OF 72 RETROSPOT CAKE CASES    |\n",
      "|WOODLAND DESIGN  COTTON TOTE BAG   |WOODLAND DESIGN  COTTON TOTE BAG   |\n",
      "|BIG DOUGHNUT FRIDGE MAGNETS        |BIG DOUGHNUT FRIDGE MAGNETS        |\n",
      "|RECYCLED PENCIL WITH RABBIT ERASER |RECYCLED PENCIL WITH RABBIT ERASER |\n",
      "|COLOR TOADSTOOL LED NIGHT LIGHT    |RED TOADSTOOL LED NIGHT LIGHT      |\n",
      "|RAIN PONCHO RETROSPOT              |RAIN PONCHO RETROSPOT              |\n",
      "|STRAWBERRY CERAMIC TRINKET BOX     |STRAWBERRY CERAMIC TRINKET BOX     |\n",
      "|6 RIBBONS RUSTIC CHARM             |6 RIBBONS RUSTIC CHARM             |\n",
      "|ROUND SNACK BOXES SET OF4 WOODLAND |ROUND SNACK BOXES SET OF4 WOODLAND |\n",
      "|REGENCY CAKESTAND 3 TIER           |REGENCY CAKESTAND 3 TIER           |\n",
      "|TV DINNER TRAY DOLLY GIRL          |TV DINNER TRAY DOLLY GIRL          |\n",
      "|PENCIL CASE LIFE IS BEAUTIFUL      |PENCIL CASE LIFE IS BEAUTIFUL      |\n",
      "|PLASTERS IN TIN WOODLAND ANIMALS   |PLASTERS IN TIN WOODLAND ANIMALS   |\n",
      "|PLASTERS IN TIN CIRCUS PARADE      |PLASTERS IN TIN CIRCUS PARADE      |\n",
      "|PLASTERS IN TIN STRONGMAN          |PLASTERS IN TIN STRONGMAN          |\n",
      "|CERAMIC STRAWBERRY CAKE MONEY BANK |CERAMIC STRAWBERRY CAKE MONEY BANK |\n",
      "|CERAMIC CHERRY CAKE MONEY BANK     |CERAMIC CHERRY CAKE MONEY BANK     |\n",
      "|STRAWBERRY FAIRY CAKE TEAPOT       |STRAWBERRY FAIRY CAKE TEAPOT       |\n",
      "|PACK OF 12 TRADITIONAL CRAYONS     |PACK OF 12 TRADITIONAL CRAYONS     |\n",
      "|PACK OF 20 NAPKINS PANTRY DESIGN   |PACK OF 20 NAPKINS PANTRY DESIGN   |\n",
      "|PACK OF 20 NAPKINS COLOR APPLES    |PACK OF 20 NAPKINS RED APPLES      |\n",
      "|OVEN MITT APPLES DESIGN            |OVEN MITT APPLES DESIGN            |\n",
      "|SET 7 BABUSHKA NESTING BOXES       |SET 7 BABUSHKA NESTING BOXES       |\n",
      "|BREAD BIN DINER STYLE PINK         |BREAD BIN DINER STYLE PINK         |\n",
      "|ALARM CLOCK BAKELIKE PINK          |ALARM CLOCK BAKELIKE PINK          |\n",
      "|HEN HOUSE W CHICK STANDING         |HEN HOUSE W CHICK STANDING         |\n",
      "|ROSE COTTAGE KEEPSAKE BOX          |ROSE COTTAGE KEEPSAKE BOX          |\n",
      "|PACK OF 12 COLOUCOLOR PENCILS      |PACK OF 12 COLOURED PENCILS        |\n",
      "|FUNKY DIVA PEN                     |FUNKY DIVA PEN                     |\n",
      "|CHEST OF DRAWERS GINGHAM HEART     |CHEST OF DRAWERS GINGHAM HEART     |\n",
      "|ROUND SNACK BOXES SET OF4 WOODLAND |ROUND SNACK BOXES SET OF4 WOODLAND |\n",
      "|TRADITIONAL KNITTING NANCY         |TRADITIONAL KNITTING NANCY         |\n",
      "|BAKING MOULD CHOCOLATE CUPCAKES    |BAKING MOULD CHOCOLATE CUPCAKES    |\n",
      "|POPPY'S PLAYHOUSE LIVINGROOM       |POPPY'S PLAYHOUSE LIVINGROOM       |\n",
      "|POPPY'S PLAYHOUSE BEDROOM          |POPPY'S PLAYHOUSE BEDROOM          |\n",
      "|POPPY'S PLAYHOUSE KITCHEN          |POPPY'S PLAYHOUSE KITCHEN          |\n",
      "|LIPSTICK PEN COLOR                 |LIPSTICK PEN RED                   |\n",
      "+-----------------------------------+-----------------------------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "simpleColors = List(black, white, red, green, blud)\n",
       "regexString = BLACK|WHITE|RED|GREEN|BLUD\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BLACK|WHITE|RED|GREEN|BLUD"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 정규 표현식\n",
    "// 문자열의 존재 여부를 확인하거나 일치하는 모든 문자열을 치환할 때 사용함.\n",
    "// regexp_replace\n",
    "\n",
    "import org.apache.spark.sql.functions.regexp_replace\n",
    "val simpleColors = Seq(\"black\", \"white\", \"red\", \"green\", \"blud\")\n",
    "val regexString = simpleColors.map(_.toUpperCase).mkString(\"|\") // 파이프문자 (|)는 정규표현식에서 or를 뜻함.\n",
    "\n",
    "df.select(\n",
    "    regexp_replace(col(\"Description\"), regexString, \"COLOR\").alias(\"color_clean\"), col(\"Description\")\n",
    ").show(50, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+-----------------------------------+\n",
      "|translate(Description, LEET, 1357) |Description                        |\n",
      "+-----------------------------------+-----------------------------------+\n",
      "|HAWAIIAN GRASS SKIR7               |HAWAIIAN GRASS SKIRT               |\n",
      "|CHI11I 1IGH7S                      |CHILLI LIGHTS                      |\n",
      "|\"R3CORD FRAM3 7\"\" SING13 SIZ3 \"    |\"RECORD FRAME 7\"\" SINGLE SIZE \"    |\n",
      "|3D DOG PIC7UR3 P1AYING CARDS       |3D DOG PICTURE PLAYING CARDS       |\n",
      "|60 CAK3 CAS3S VIN7AG3 CHRIS7MAS    |60 CAKE CASES VINTAGE CHRISTMAS    |\n",
      "|PAP3R CHAIN KI7 VIN7AG3 CHRIS7MAS  |PAPER CHAIN KIT VINTAGE CHRISTMAS  |\n",
      "|CHRIS7MAS 7OI137 RO11              |CHRISTMAS TOILET ROLL              |\n",
      "|\"ASSOR73D F1OW3R CO1OUR \"\"13IS\"\"\"  |\"ASSORTED FLOWER COLOUR \"\"LEIS\"\"\"  |\n",
      "|I CAN ON1Y P13AS3 ON3 P3RSON MUG   |I CAN ONLY PLEASE ONE PERSON MUG   |\n",
      "|HAND WARM3R BABUSHKA D3SIGN        |HAND WARMER BABUSHKA DESIGN        |\n",
      "|B1U3 HARMONICA IN BOX              |BLUE HARMONICA IN BOX              |\n",
      "|null                               |null                               |\n",
      "|S37 OF 72 R37ROSPO7 PAP3R  DOI1I3S |SET OF 72 RETROSPOT PAPER  DOILIES |\n",
      "|PACK OF 72 R37ROSPO7 CAK3 CAS3S    |PACK OF 72 RETROSPOT CAKE CASES    |\n",
      "|WOOD1AND D3SIGN  CO77ON 7O73 BAG   |WOODLAND DESIGN  COTTON TOTE BAG   |\n",
      "|BIG DOUGHNU7 FRIDG3 MAGN37S        |BIG DOUGHNUT FRIDGE MAGNETS        |\n",
      "|R3CYC13D P3NCI1 WI7H RABBI7 3RAS3R |RECYCLED PENCIL WITH RABBIT ERASER |\n",
      "|R3D 7OADS7OO1 13D NIGH7 1IGH7      |RED TOADSTOOL LED NIGHT LIGHT      |\n",
      "|RAIN PONCHO R37ROSPO7              |RAIN PONCHO RETROSPOT              |\n",
      "|S7RAWB3RRY C3RAMIC 7RINK37 BOX     |STRAWBERRY CERAMIC TRINKET BOX     |\n",
      "|6 RIBBONS RUS7IC CHARM             |6 RIBBONS RUSTIC CHARM             |\n",
      "|ROUND SNACK BOX3S S37 OF4 WOOD1AND |ROUND SNACK BOXES SET OF4 WOODLAND |\n",
      "|R3G3NCY CAK3S7AND 3 7I3R           |REGENCY CAKESTAND 3 TIER           |\n",
      "|7V DINN3R 7RAY DO11Y GIR1          |TV DINNER TRAY DOLLY GIRL          |\n",
      "|P3NCI1 CAS3 1IF3 IS B3AU7IFU1      |PENCIL CASE LIFE IS BEAUTIFUL      |\n",
      "|P1AS73RS IN 7IN WOOD1AND ANIMA1S   |PLASTERS IN TIN WOODLAND ANIMALS   |\n",
      "|P1AS73RS IN 7IN CIRCUS PARAD3      |PLASTERS IN TIN CIRCUS PARADE      |\n",
      "|P1AS73RS IN 7IN S7RONGMAN          |PLASTERS IN TIN STRONGMAN          |\n",
      "|C3RAMIC S7RAWB3RRY CAK3 MON3Y BANK |CERAMIC STRAWBERRY CAKE MONEY BANK |\n",
      "|C3RAMIC CH3RRY CAK3 MON3Y BANK     |CERAMIC CHERRY CAKE MONEY BANK     |\n",
      "|S7RAWB3RRY FAIRY CAK3 73APO7       |STRAWBERRY FAIRY CAKE TEAPOT       |\n",
      "|PACK OF 12 7RADI7IONA1 CRAYONS     |PACK OF 12 TRADITIONAL CRAYONS     |\n",
      "|PACK OF 20 NAPKINS PAN7RY D3SIGN   |PACK OF 20 NAPKINS PANTRY DESIGN   |\n",
      "|PACK OF 20 NAPKINS R3D APP13S      |PACK OF 20 NAPKINS RED APPLES      |\n",
      "|OV3N MI77 APP13S D3SIGN            |OVEN MITT APPLES DESIGN            |\n",
      "|S37 7 BABUSHKA N3S7ING BOX3S       |SET 7 BABUSHKA NESTING BOXES       |\n",
      "|BR3AD BIN DIN3R S7Y13 PINK         |BREAD BIN DINER STYLE PINK         |\n",
      "|A1ARM C1OCK BAK31IK3 PINK          |ALARM CLOCK BAKELIKE PINK          |\n",
      "|H3N HOUS3 W CHICK S7ANDING         |HEN HOUSE W CHICK STANDING         |\n",
      "|ROS3 CO77AG3 K33PSAK3 BOX          |ROSE COTTAGE KEEPSAKE BOX          |\n",
      "|PACK OF 12 CO1OUR3D P3NCI1S        |PACK OF 12 COLOURED PENCILS        |\n",
      "|FUNKY DIVA P3N                     |FUNKY DIVA PEN                     |\n",
      "|CH3S7 OF DRAW3RS GINGHAM H3AR7     |CHEST OF DRAWERS GINGHAM HEART     |\n",
      "|ROUND SNACK BOX3S S37 OF4 WOOD1AND |ROUND SNACK BOXES SET OF4 WOODLAND |\n",
      "|7RADI7IONA1 KNI77ING NANCY         |TRADITIONAL KNITTING NANCY         |\n",
      "|BAKING MOU1D CHOCO1A73 CUPCAK3S    |BAKING MOULD CHOCOLATE CUPCAKES    |\n",
      "|POPPY'S P1AYHOUS3 1IVINGROOM       |POPPY'S PLAYHOUSE LIVINGROOM       |\n",
      "|POPPY'S P1AYHOUS3 B3DROOM          |POPPY'S PLAYHOUSE BEDROOM          |\n",
      "|POPPY'S P1AYHOUS3 KI7CH3N          |POPPY'S PLAYHOUSE KITCHEN          |\n",
      "|1IPS7ICK P3N R3D                   |LIPSTICK PEN RED                   |\n",
      "+-----------------------------------+-----------------------------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// translate 함수를 사용해 문자 치환\n",
    "import org.apache.spark.sql.functions.translate\n",
    "\n",
    "// 연산은 문자 단위로 이루어짐.\n",
    "df.select(translate(col(\"Description\"), \"LEET\", \"1337\"), col(\"Description\")).show(50, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------------------------+\n",
      "|color_clean|Description                        |\n",
      "+-----------+-----------------------------------+\n",
      "|           |HAWAIIAN GRASS SKIRT               |\n",
      "|           |CHILLI LIGHTS                      |\n",
      "|           |\"RECORD FRAME 7\"\" SINGLE SIZE \"    |\n",
      "|           |3D DOG PICTURE PLAYING CARDS       |\n",
      "|           |60 CAKE CASES VINTAGE CHRISTMAS    |\n",
      "|           |PAPER CHAIN KIT VINTAGE CHRISTMAS  |\n",
      "|           |CHRISTMAS TOILET ROLL              |\n",
      "|           |\"ASSORTED FLOWER COLOUR \"\"LEIS\"\"\"  |\n",
      "|           |I CAN ONLY PLEASE ONE PERSON MUG   |\n",
      "|           |HAND WARMER BABUSHKA DESIGN        |\n",
      "|           |BLUE HARMONICA IN BOX              |\n",
      "|null       |null                               |\n",
      "|           |SET OF 72 RETROSPOT PAPER  DOILIES |\n",
      "|           |PACK OF 72 RETROSPOT CAKE CASES    |\n",
      "|           |WOODLAND DESIGN  COTTON TOTE BAG   |\n",
      "|           |BIG DOUGHNUT FRIDGE MAGNETS        |\n",
      "|           |RECYCLED PENCIL WITH RABBIT ERASER |\n",
      "|RED        |RED TOADSTOOL LED NIGHT LIGHT      |\n",
      "|           |RAIN PONCHO RETROSPOT              |\n",
      "|           |STRAWBERRY CERAMIC TRINKET BOX     |\n",
      "|           |6 RIBBONS RUSTIC CHARM             |\n",
      "|           |ROUND SNACK BOXES SET OF4 WOODLAND |\n",
      "|           |REGENCY CAKESTAND 3 TIER           |\n",
      "|           |TV DINNER TRAY DOLLY GIRL          |\n",
      "|           |PENCIL CASE LIFE IS BEAUTIFUL      |\n",
      "|           |PLASTERS IN TIN WOODLAND ANIMALS   |\n",
      "|           |PLASTERS IN TIN CIRCUS PARADE      |\n",
      "|           |PLASTERS IN TIN STRONGMAN          |\n",
      "|           |CERAMIC STRAWBERRY CAKE MONEY BANK |\n",
      "|           |CERAMIC CHERRY CAKE MONEY BANK     |\n",
      "|           |STRAWBERRY FAIRY CAKE TEAPOT       |\n",
      "|           |PACK OF 12 TRADITIONAL CRAYONS     |\n",
      "|           |PACK OF 20 NAPKINS PANTRY DESIGN   |\n",
      "|RED        |PACK OF 20 NAPKINS RED APPLES      |\n",
      "|           |OVEN MITT APPLES DESIGN            |\n",
      "|           |SET 7 BABUSHKA NESTING BOXES       |\n",
      "|           |BREAD BIN DINER STYLE PINK         |\n",
      "|           |ALARM CLOCK BAKELIKE PINK          |\n",
      "|           |HEN HOUSE W CHICK STANDING         |\n",
      "|           |ROSE COTTAGE KEEPSAKE BOX          |\n",
      "|RED        |PACK OF 12 COLOURED PENCILS        |\n",
      "|           |FUNKY DIVA PEN                     |\n",
      "|           |CHEST OF DRAWERS GINGHAM HEART     |\n",
      "|           |ROUND SNACK BOXES SET OF4 WOODLAND |\n",
      "|           |TRADITIONAL KNITTING NANCY         |\n",
      "|           |BAKING MOULD CHOCOLATE CUPCAKES    |\n",
      "|           |POPPY'S PLAYHOUSE LIVINGROOM       |\n",
      "|           |POPPY'S PLAYHOUSE BEDROOM          |\n",
      "|           |POPPY'S PLAYHOUSE KITCHEN          |\n",
      "|RED        |LIPSTICK PEN RED                   |\n",
      "+-----------+-----------------------------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "regexString = (BLACK|WHITE|RED|GREEN|BLUD)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(BLACK|WHITE|RED|GREEN|BLUD)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.regexp_extract\n",
    "\n",
    "// 처음 나타난 색상 이름을 추출하는 작업\n",
    "val regexString = simpleColors.map(_.toUpperCase).mkString(\"(\",\"|\",\")\")\n",
    "\n",
    "df.select(regexp_extract(col(\"Description\"), regexString, 1).alias(\"color_clean\"), col(\"Description\")).show(50, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+\n",
      "|Description                       |\n",
      "+----------------------------------+\n",
      "|BAKING MOULD EASTER EGG WHITE CHOC|\n",
      "|WHITE HANGING HEART T-LIGHT HOLDER|\n",
      "|EDWARDIAN PARASOL BLACK           |\n",
      "|BLACK EAR MUFF HEADPHONES         |\n",
      "|BLACK RECORD COVER FRAME          |\n",
      "+----------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "containsBlack = contains(Description, BLACK)\n",
       "containsWhite = contains(Description, WHITE)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "contains(Description, WHITE)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 값 추출이 아닌 값의 존재 여부 확인\n",
    "val containsBlack = col(\"Description\").contains(\"BLACK\")\n",
    "val containsWhite = col(\"Description\").contains(\"WHITE\")\n",
    "\n",
    "df.withColumn(\"hasSimpleColor\", containsBlack.or(containsWhite))\n",
    "    .where(\"hasSimpleColor\").select(\"Description\").show(5, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Unknown Error\n",
       "Message: lastException: Throwable = null\n",
       "<console>:36: error: not found: value expr\n",
       "       }):+expr(\"*\")\n",
       "           ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 동적으로 인수의 개수가 변하는 경우 (???)\n",
    "/// ???????????????????????????????????????????????????????????????\n",
    "val simpleColors = Seq(\"black\",\"white\",\"red\",\"green\",\"blud\")\n",
    "val selectedColumns = simpleColors.map(color => {\n",
    "    col(\"Description\").contains(color.toUpperCase).alias(s\"is_$color\")\n",
    "}):+expr(\"*\")\n",
    "\n",
    "df.select(selectedColumns:_*).where(col(\"is_white\").or(col(\"is_red\"))).select(\"Description\").show(5, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 날짜와 타임스탬프 데이터 다루기\n",
    "\n",
    "날짜와 시간은 프로그래밍 언어와 데이터베이스 분야의 변함없는 과제이다. <br>\n",
    "계속해 시간대를 확인해야 하며, 포맷이 올바르고 유효한지 확인해야 한다. <br>\n",
    "이러한 복잡함을 피하고자 두 종류의 시간 관련 정보만 집중적으로 관리함. (달력 형태의 data, 날짜, 시간 정보를 가지는 timestamp) <br>\n",
    "스파크 inferSchema 옵션이 활성화된 경우 날짜와 타임스탬프를 포함하 컬럼을 최대한 정확히 식별하려 노력함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----------------------+\n",
      "|id |today     |now                    |\n",
      "+---+----------+-----------------------+\n",
      "|0  |2019-07-26|2019-07-26 11:25:37.561|\n",
      "|1  |2019-07-26|2019-07-26 11:25:37.561|\n",
      "|2  |2019-07-26|2019-07-26 11:25:37.561|\n",
      "|3  |2019-07-26|2019-07-26 11:25:37.561|\n",
      "|4  |2019-07-26|2019-07-26 11:25:37.561|\n",
      "|5  |2019-07-26|2019-07-26 11:25:37.561|\n",
      "|6  |2019-07-26|2019-07-26 11:25:37.561|\n",
      "|7  |2019-07-26|2019-07-26 11:25:37.561|\n",
      "|8  |2019-07-26|2019-07-26 11:25:37.561|\n",
      "|9  |2019-07-26|2019-07-26 11:25:37.561|\n",
      "+---+----------+-----------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dateDF = [id: bigint, today: date ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[id: bigint, today: date ... 1 more field]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.{current_date, current_timestamp}\n",
    "\n",
    "val dateDF = sc.range(10)\n",
    "    .withColumn(\"today\", current_date())\n",
    "    .withColumn(\"now\", current_timestamp())\n",
    "dateDF.createOrReplaceTempView(\"dataTable\")\n",
    "dateDF.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|date_sub(today, 5)|date_add(today, 5)|\n",
      "+------------------+------------------+\n",
      "|        2019-07-21|        2019-07-31|\n",
      "+------------------+------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.{date_add, date_sub}\n",
    "\n",
    "// 날짜 계산 5일 전후로.\n",
    "dateDF.select(date_sub(col(\"today\"), 5), date_add(col(\"today\"), 5)).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|datediff(week_ago, today)|\n",
      "+-------------------------+\n",
      "|                       -7|\n",
      "+-------------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "+--------------------------------+\n",
      "|months_between(start, end, true)|\n",
      "+--------------------------------+\n",
      "|                    -16.67741935|\n",
      "+--------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.{datediff, months_between, to_date}\n",
    "\n",
    "// 날짜간 일 차이 계산.\n",
    "dateDF.withColumn(\"week_ago\", date_sub(col(\"today\"), 7))\n",
    "    .select(datediff(col(\"week_ago\"), col(\"today\"))).show(1)\n",
    "\n",
    "// 날짜간 월 차이 계산\n",
    "// to_date는 문자열을 날짜로 변환할 수 있으며, 필요에 따라 날짜 포맷도 지정할 수 있음.\n",
    "// 함수의 날짜 포맷은 자바의 SimpleDataFormat 클래스가 지원하는 포맷을 사용해야 함.\n",
    "dateDF.select(\n",
    "    to_date(lit(\"2016-01-01\")).alias(\"start\"),\n",
    "    to_date(lit(\"2017-05-22\")).alias(\"end\")\n",
    ").select(months_between(col(\"start\"), col(\"end\"))).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|to_date(`date`)|\n",
      "+---------------+\n",
      "|     2017-01-01|\n",
      "+---------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.{to_date, lit}\n",
    "\n",
    "sc.range(5).withColumn(\"date\", lit(\"2017-01-01\"))\n",
    "    .select(to_date(col(\"date\"))).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|to_date('2016-20-12')|\n",
      "+---------------------+\n",
      "|                 null|\n",
      "+---------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "+---------------------+\n",
      "|to_date('2016-12-11')|\n",
      "+---------------------+\n",
      "|           2016-12-11|\n",
      "+---------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// 파싱 할수 없는 날짜는 null을 출력 (yyyy-dd-MM) 이라 생각했을 때.\n",
    "dateDF.select(to_date(lit(\"2016-20-12\"))).show(1)\n",
    "dateDF.select(to_date(lit(\"2017-12-11\"))).show(1) // 얘는 에러라 판단하기가 힘듦."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|      date|     date2|\n",
      "+----------+----------+\n",
      "|2017-01-12|2017-01-20|\n",
      "+----------+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dateFormat = yyyy-dd-mm\n",
       "cleanDateDF = [date: date, date2: date]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[date: date, date2: date]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 위는 날짜 포맷을 입혀서 처리할 것.\n",
    "import org.apache.spark.sql.functions.to_date\n",
    "\n",
    "val dateFormat = \"yyyy-dd-MM\"\n",
    "val cleanDateDF = sc.range(1).select(\n",
    "    to_date(lit(\"2017-12-11\"), dateFormat).alias(\"date\"),\n",
    "    to_date(lit(\"2017-20-12\"), dateFormat).alias(\"date2\")\n",
    ")\n",
    "cleanDateDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+\n",
      "|to_timestamp(`date`, 'yyyy-dd-MM')|\n",
      "+----------------------------------+\n",
      "|               2017-11-12 00:00:00|\n",
      "+----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// timestamp는 항상 날짜 포맷을 지정해야함.\n",
    "import org.apache.spark.sql.functions.to_timestamp\n",
    "\n",
    "cleanDateDF.select(to_timestamp(col(\"date\"), dateFormat)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|      date|     date2|\n",
      "+----------+----------+\n",
      "|2017-11-12|2017-12-20|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// 올바른 포맷과 타입의 날짜나 타임스탬프를 사용한다면 매우 쉽게 비교 연산도 가능\n",
    "cleanDateDF.filter(col(\"date2\") > lit(\"2017-12-12\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 널값 다루기\n",
    "Dataframe에서는 빠져있거나 비어있는 데이터는 항상 null을 사용하는것이 좋음. <br>\n",
    "빈 문자열이나 대체 값 대신 null값을 사용해야 최적화를 수행할 수 있음. <br>\n",
    "Dataframe에 하위 패키지인 .na를 사용하는 것이 null을 다룰 수 있는 기본 방식."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+\n",
      "|coalesce(Description, CustomerId) |\n",
      "+----------------------------------+\n",
      "|HAWAIIAN GRASS SKIRT              |\n",
      "|CHILLI LIGHTS                     |\n",
      "|\"RECORD FRAME 7\"\" SINGLE SIZE \"   |\n",
      "|3D DOG PICTURE PLAYING CARDS      |\n",
      "|60 CAKE CASES VINTAGE CHRISTMAS   |\n",
      "|PAPER CHAIN KIT VINTAGE CHRISTMAS |\n",
      "|CHRISTMAS TOILET ROLL             |\n",
      "|\"ASSORTED FLOWER COLOUR \"\"LEIS\"\"\" |\n",
      "|I CAN ONLY PLEASE ONE PERSON MUG  |\n",
      "|HAND WARMER BABUSHKA DESIGN       |\n",
      "|BLUE HARMONICA IN BOX             |\n",
      "|null                              |\n",
      "|SET OF 72 RETROSPOT PAPER  DOILIES|\n",
      "|PACK OF 72 RETROSPOT CAKE CASES   |\n",
      "|WOODLAND DESIGN  COTTON TOTE BAG  |\n",
      "|BIG DOUGHNUT FRIDGE MAGNETS       |\n",
      "|RECYCLED PENCIL WITH RABBIT ERASER|\n",
      "|RED TOADSTOOL LED NIGHT LIGHT     |\n",
      "|RAIN PONCHO RETROSPOT             |\n",
      "|STRAWBERRY CERAMIC TRINKET BOX    |\n",
      "+----------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------------------------------+----------+\n",
      "|Description                       |CustomerId|\n",
      "+----------------------------------+----------+\n",
      "|HAWAIIAN GRASS SKIRT              |15805.0   |\n",
      "|CHILLI LIGHTS                     |15805.0   |\n",
      "|\"RECORD FRAME 7\"\" SINGLE SIZE \"   |15805.0   |\n",
      "|3D DOG PICTURE PLAYING CARDS      |15805.0   |\n",
      "|60 CAKE CASES VINTAGE CHRISTMAS   |15805.0   |\n",
      "|PAPER CHAIN KIT VINTAGE CHRISTMAS |15805.0   |\n",
      "|CHRISTMAS TOILET ROLL             |15805.0   |\n",
      "|\"ASSORTED FLOWER COLOUR \"\"LEIS\"\"\" |15805.0   |\n",
      "|I CAN ONLY PLEASE ONE PERSON MUG  |15805.0   |\n",
      "|HAND WARMER BABUSHKA DESIGN       |15805.0   |\n",
      "|BLUE HARMONICA IN BOX             |15805.0   |\n",
      "|null                              |null      |\n",
      "|SET OF 72 RETROSPOT PAPER  DOILIES|12471.0   |\n",
      "|PACK OF 72 RETROSPOT CAKE CASES   |12471.0   |\n",
      "|WOODLAND DESIGN  COTTON TOTE BAG  |12471.0   |\n",
      "|BIG DOUGHNUT FRIDGE MAGNETS       |12471.0   |\n",
      "|RECYCLED PENCIL WITH RABBIT ERASER|12471.0   |\n",
      "|RED TOADSTOOL LED NIGHT LIGHT     |12471.0   |\n",
      "|RAIN PONCHO RETROSPOT             |12471.0   |\n",
      "|STRAWBERRY CERAMIC TRINKET BOX    |12471.0   |\n",
      "+----------------------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// coalesce\n",
    "// 인수로 지정한 여러 컬럼 중 null이 아닌 첫번 째 값을 반환함.\n",
    "import org.apache.spark.sql.functions.coalesce\n",
    "\n",
    "df.select(coalesce(col(\"Description\"), col(\"CustomerId\"))).show(20, false)\n",
    "df.select(col(\"Description\"), col(\"CustomerId\")).show(20, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ifnull: 첫번째 값이 null이면 두번째 값을 반환함, 첫번쨰 값이 null이 아니면 첫번쨰 값을 반환함. <br>\n",
    "nullif: 두 값이 같으면 null을 반환함. 두 값이 다르면 첫번쨰 값을 반환함.<br>\n",
    "nvl: ifnull 동일<br>\n",
    "nvl2: 첫번째 값이 null이면 세번째 인수로 지정한 값을 반환함. 첫번째 값이 null이 아니면 두번째 값을 반환함. <br>\n",
    "<br>\n",
    "SELECT<br>\n",
    " ifnull(null, 'return_value'),<br>\n",
    " nullif('value', 'value'),<br>\n",
    " nvl(null, 'return_value'),<br>\n",
    " nvl2('not_null', 'return_value', 'else_value')<br>\n",
    "<br>\n",
    "a--> return_value<br>\n",
    "b-->null<br>\n",
    "c-->return_value<br>\n",
    "d-->return_value<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   538172|    21562|HAWAIIAN GRASS SK...|      12|2010-12-10 09:33:00|     1.25|   15805.0|United Kingdom|\n",
      "|   538172|    79321|       CHILLI LIGHTS|       8|2010-12-10 09:33:00|     4.95|   15805.0|United Kingdom|\n",
      "|   538172|    22041|\"RECORD FRAME 7\"\"...|      12|2010-12-10 09:33:00|     2.55|   15805.0|United Kingdom|\n",
      "|   538172|   84558A|3D DOG PICTURE PL...|      12|2010-12-10 09:33:00|     2.95|   15805.0|United Kingdom|\n",
      "|   538172|    22952|60 CAKE CASES VIN...|      24|2010-12-10 09:33:00|     0.55|   15805.0|United Kingdom|\n",
      "|   538172|    22910|PAPER CHAIN KIT V...|      24|2010-12-10 09:33:00|     2.95|   15805.0|United Kingdom|\n",
      "|   538172|    21098|CHRISTMAS TOILET ...|      24|2010-12-10 09:33:00|     1.25|   15805.0|United Kingdom|\n",
      "|   538172|    84212|\"ASSORTED FLOWER ...|      24|2010-12-10 09:33:00|     0.65|   15805.0|United Kingdom|\n",
      "|   538172|    21870|I CAN ONLY PLEASE...|      12|2010-12-10 09:33:00|     1.25|   15805.0|United Kingdom|\n",
      "|   538172|    22834|HAND WARMER BABUS...|      36|2010-12-10 09:33:00|      2.1|   15805.0|United Kingdom|\n",
      "|   538172|    21914|BLUE HARMONICA IN...|      24|2010-12-10 09:33:00|     1.25|   15805.0|United Kingdom|\n",
      "|   538174|    21210|SET OF 72 RETROSP...|      12|2010-12-10 09:35:00|     1.45|   12471.0|       Germany|\n",
      "|   538174|    21212|PACK OF 72 RETROS...|      24|2010-12-10 09:35:00|     0.55|   12471.0|       Germany|\n",
      "|   538174|    21578|WOODLAND DESIGN  ...|      24|2010-12-10 09:35:00|     2.25|   12471.0|       Germany|\n",
      "|   538174|    21700|BIG DOUGHNUT FRID...|      72|2010-12-10 09:35:00|     0.85|   12471.0|       Germany|\n",
      "|   538174|    16235|RECYCLED PENCIL W...|      60|2010-12-10 09:35:00|     0.21|   12471.0|       Germany|\n",
      "|   538174|    21731|RED TOADSTOOL LED...|      48|2010-12-10 09:35:00|     1.65|   12471.0|       Germany|\n",
      "|   538174|    21787|RAIN PONCHO RETRO...|      24|2010-12-10 09:35:00|     0.85|   12471.0|       Germany|\n",
      "|   538174|    21232|STRAWBERRY CERAMI...|      36|2010-12-10 09:35:00|     1.25|   12471.0|       Germany|\n",
      "|   538174|    22077|6 RIBBONS RUSTIC ...|      24|2010-12-10 09:35:00|     1.65|   12471.0|       Germany|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// drop: null값을 가진 로우를 제거하는 함수\n",
    "df.na.drop() \n",
    "df.na.drop(\"any\") // 로우의 컬럼 중 하나라도 null이라면 해당 로우를 제거함.\n",
    "df.na.drop(\"all\") // 모든 컬럼의 값이 null이거나 NaN 인 경우에만 로우를 제거함.\n",
    "\n",
    "df.na.drop(\"all\", Seq(\"StockCode\", \"InvoiceNo\")) // 특정 컬럼을 인수로 전달할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[InvoiceNo: string, StockCode: string ... 6 more fields]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// fill: 하나 이상의 컬럼을 특정 값으로 채울 수 있음.\n",
    "df.na.fill(\"All Null values become this string\")\n",
    "df.na.fill(5, Seq(\"StockCode\", \"InvoiceNo\")) // 특정 컬럼을 인수로 받을 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fillColValues = Map(StockCode -> 5, Description -> No Value)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[InvoiceNo: string, StockCode: string ... 6 more fields]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Map 타입을 사용해 다수의 컬럼에 fill 메서드를 적용함\n",
    "val fillColValues = Map(\"StockCode\" -> 5, \"Description\" -> \"No Value\")\n",
    "df.na.fill(fillColValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description                    |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+-------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "|538172   |21562    |HAWAIIAN GRASS SKIRT           |12      |2010-12-10 09:33:00|1.25     |15805.0   |United Kingdom|\n",
      "|538172   |79321    |CHILLI LIGHTS                  |8       |2010-12-10 09:33:00|4.95     |15805.0   |United Kingdom|\n",
      "|538172   |22041    |\"RECORD FRAME 7\"\" SINGLE SIZE \"|12      |2010-12-10 09:33:00|2.55     |15805.0   |United Kingdom|\n",
      "|538172   |84558A   |3D DOG PICTURE PLAYING CARDS   |12      |2010-12-10 09:33:00|2.95     |15805.0   |United Kingdom|\n",
      "|538172   |22952    |60 CAKE CASES VINTAGE CHRISTMAS|24      |2010-12-10 09:33:00|0.55     |15805.0   |United Kingdom|\n",
      "+---------+---------+-------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// replace: fill메서드 외에 null값을 유연하게 대처하기 위함. 조건에 따라 다른 값으로 대체함\n",
    "df.na.replace(\"Description\", Map(\"\" -> \"UNKNOWN\")).show(5, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 정렬하기\n",
    "\n",
    "5장에서 설명한 것처럼 acs_nulls_first, desc_nulls_first, acs_nulls,last, desc_nulls_last 함수를 사용해 Dataframe 을 정렬할 때 null값이 표시되는 기준으로 지정할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. 복합 데이터 타입 다루기\n",
    "\n",
    "복합 데이터 타입은 구조체, 배열, 맵이 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------+\n",
      "|complex                                    |\n",
      "+-------------------------------------------+\n",
      "|[HAWAIIAN GRASS SKIRT , 538172]            |\n",
      "|[CHILLI LIGHTS, 538172]                    |\n",
      "|[\"RECORD FRAME 7\"\" SINGLE SIZE \", 538172]  |\n",
      "|[3D DOG PICTURE PLAYING CARDS, 538172]     |\n",
      "|[60 CAKE CASES VINTAGE CHRISTMAS, 538172]  |\n",
      "|[PAPER CHAIN KIT VINTAGE CHRISTMAS, 538172]|\n",
      "|[CHRISTMAS TOILET ROLL, 538172]            |\n",
      "|[\"ASSORTED FLOWER COLOUR \"\"LEIS\"\"\", 538172]|\n",
      "|[I CAN ONLY PLEASE ONE PERSON MUG, 538172] |\n",
      "|[HAND WARMER BABUSHKA DESIGN, 538172]      |\n",
      "+-------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "complexDF = [complex: struct<Description: string, InvoiceNo: string>]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[complex: struct<Description: string, InvoiceNo: string>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 구조체: Dataframe 내부의 Dataframe으로 생각할 수 있음.\n",
    "import org.apache.spark.sql.functions.struct\n",
    "\n",
    "val complexDF = df.select(struct(\"Description\", \"InvoiceNo\").alias(\"complex\"))\n",
    "complexDF.createOrReplaceTempView(\"complexDF\")\n",
    "complexDF.show(10, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+\n",
      "|Description                      |\n",
      "+---------------------------------+\n",
      "|HAWAIIAN GRASS SKIRT             |\n",
      "|CHILLI LIGHTS                    |\n",
      "|\"RECORD FRAME 7\"\" SINGLE SIZE \"  |\n",
      "|3D DOG PICTURE PLAYING CARDS     |\n",
      "|60 CAKE CASES VINTAGE CHRISTMAS  |\n",
      "|PAPER CHAIN KIT VINTAGE CHRISTMAS|\n",
      "|CHRISTMAS TOILET ROLL            |\n",
      "|\"ASSORTED FLOWER COLOUR \"\"LEIS\"\"\"|\n",
      "|I CAN ONLY PLEASE ONE PERSON MUG |\n",
      "|HAND WARMER BABUSHKA DESIGN      |\n",
      "+---------------------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+---------------------------------+\n",
      "|complex.Description              |\n",
      "+---------------------------------+\n",
      "|HAWAIIAN GRASS SKIRT             |\n",
      "|CHILLI LIGHTS                    |\n",
      "|\"RECORD FRAME 7\"\" SINGLE SIZE \"  |\n",
      "|3D DOG PICTURE PLAYING CARDS     |\n",
      "|60 CAKE CASES VINTAGE CHRISTMAS  |\n",
      "|PAPER CHAIN KIT VINTAGE CHRISTMAS|\n",
      "|CHRISTMAS TOILET ROLL            |\n",
      "|\"ASSORTED FLOWER COLOUR \"\"LEIS\"\"\"|\n",
      "|I CAN ONLY PLEASE ONE PERSON MUG |\n",
      "|HAND WARMER BABUSHKA DESIGN      |\n",
      "+---------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// 점을 사용해 getField 메서드를 사용할 수 있음.\n",
    "complexDF.select(\"complex.Description\").show(10, false)\n",
    "complexDF.select(col(\"complex\").getField(\"Description\")).show(10, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+\n",
      "|split(Description,  )                 |\n",
      "+--------------------------------------+\n",
      "|[HAWAIIAN, GRASS, SKIRT, ]            |\n",
      "|[CHILLI, LIGHTS]                      |\n",
      "|[\"RECORD, FRAME, 7\"\", SINGLE, SIZE, \"]|\n",
      "|[3D, DOG, PICTURE, PLAYING, CARDS]    |\n",
      "|[60, CAKE, CASES, VINTAGE, CHRISTMAS] |\n",
      "+--------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// 배열\n",
    "// split을 통해 배열로 변환함.\n",
    "import org.apache.spark.sql.functions.split\n",
    "\n",
    "df.select(split(col(\"Description\"), \" \")).show(5, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|array_col[0]|\n",
      "+------------+\n",
      "|HAWAIIAN    |\n",
      "|CHILLI      |\n",
      "|\"RECORD     |\n",
      "|3D          |\n",
      "|60          |\n",
      "+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(split(col(\"Description\"), \" \").alias(\"array_col\"))\n",
    "    .selectExpr(\"array_col[0]\").show(5, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|size(split(Description,  ))|\n",
      "+---------------------------+\n",
      "|4                          |\n",
      "|2                          |\n",
      "|6                          |\n",
      "|5                          |\n",
      "|5                          |\n",
      "+---------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// 배열의 길이 (size 함수)\n",
    "import org.apache.spark.sql.functions.size\n",
    "\n",
    "df.select(size(split(col(\"Description\"), \" \"))).show(5, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+\n",
      "|array_contains(split(Description,  ), WHITE)|\n",
      "+--------------------------------------------+\n",
      "|false                                       |\n",
      "|false                                       |\n",
      "|false                                       |\n",
      "|false                                       |\n",
      "|false                                       |\n",
      "+--------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// 배열에 특정 값이 존재하는지 확인 (array_contains 함수)\n",
    "import org.apache.spark.sql.functions.array_contains\n",
    "\n",
    "df.select(array_contains(split(col(\"Description\"), \" \"), \"WHITE\")).show(5, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------------------------+--------+\n",
      "|Description          |splitted                  |exploded|\n",
      "+---------------------+--------------------------+--------+\n",
      "|HAWAIIAN GRASS SKIRT |[HAWAIIAN, GRASS, SKIRT, ]|HAWAIIAN|\n",
      "|HAWAIIAN GRASS SKIRT |[HAWAIIAN, GRASS, SKIRT, ]|GRASS   |\n",
      "|HAWAIIAN GRASS SKIRT |[HAWAIIAN, GRASS, SKIRT, ]|SKIRT   |\n",
      "|HAWAIIAN GRASS SKIRT |[HAWAIIAN, GRASS, SKIRT, ]|        |\n",
      "|CHILLI LIGHTS        |[CHILLI, LIGHTS]          |CHILLI  |\n",
      "+---------------------+--------------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// explode: 배열 타입의 컬럼을 입력 받음. 입력된 컬럼의 배열 값에 포함된 모든 값을 로우로 변환함.\n",
    "import org.apache.spark.sql.functions.{split, explode}\n",
    "\n",
    "df.withColumn(\"splitted\", split(col(\"Description\"), \" \"))\n",
    "    .withColumn(\"exploded\", explode(col(\"splitted\")))\n",
    "    .select(\"Description\", \"splitted\", \"exploded\").show(5, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------+\n",
      "|complex_map                                |\n",
      "+-------------------------------------------+\n",
      "|[HAWAIIAN GRASS SKIRT  -> 538172]          |\n",
      "|[CHILLI LIGHTS -> 538172]                  |\n",
      "|[\"RECORD FRAME 7\"\" SINGLE SIZE \" -> 538172]|\n",
      "|[3D DOG PICTURE PLAYING CARDS -> 538172]   |\n",
      "|[60 CAKE CASES VINTAGE CHRISTMAS -> 538172]|\n",
      "+-------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Map\n",
    "import org.apache.spark.sql.functions.map\n",
    "\n",
    "df.select(map(col(\"Description\"), col(\"InvoiceNo\")).alias(\"complex_map\")).show(5, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+\n",
      "|complex_map[HAWAIIAN GRASS SKIRT ]|\n",
      "+----------------------------------+\n",
      "|538172                            |\n",
      "|null                              |\n",
      "|null                              |\n",
      "|null                              |\n",
      "|null                              |\n",
      "+----------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// 적합한 키를 사용해 데이터를 조회할 수 있다. 없다면 null을 반환\n",
    "df.select(map(col(\"Description\"), col(\"InvoiceNo\")).alias(\"complex_map\"))\n",
    "    .selectExpr(\"complex_map['HAWAIIAN GRASS SKIRT ']\").show(5, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------+\n",
      "|key                  |value |\n",
      "+---------------------+------+\n",
      "|HAWAIIAN GRASS SKIRT |538172|\n",
      "|CHILLI LIGHTS        |538172|\n",
      "+---------------------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// map을 분해해 컬럼으로 변환할 수 있음.\n",
    "df.select(map(col(\"Description\"), col(\"InvoiceNo\")).alias(\"complex_map\"))\n",
    ".selectExpr(\"explode(complex_map)\").show(2, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Json 다루기\n",
    "\n",
    "json을 위한 몇가지 고유 기능을 지원함. <br>\n",
    "문자열 형태의 json을 직접 조작할 수 있으며, json 파싱, json 객체로 만들 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jsonDF = [jsonString: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[jsonString: string]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val jsonDF = sc.range(1).selectExpr(\"\"\"\n",
    "    '{\"myJsonKey\": {\"myJsonValue\":[1, 2, 3]}}' as jsonString \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------------+\n",
      "|column|c0                     |\n",
      "+------+-----------------------+\n",
      "|2     |{\"myJsonValue\":[1,2,3]}|\n",
      "+------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.{get_json_object, json_tuple}\n",
    "\n",
    "jsonDF.select(\n",
    "    get_json_object(col(\"jsonString\"), \"$.myJsonKey.myJsonValue[1]\") as \"column\", \n",
    "    json_tuple(col(\"jsonString\"), \"myJsonKey\")\n",
    ").show(2, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+\n",
      "|structstojson(myStruct)                                     |\n",
      "+------------------------------------------------------------+\n",
      "|{\"InvoiceNo\":\"538172\",\"Description\":\"HAWAIIAN GRASS SKIRT \"}|\n",
      "|{\"InvoiceNo\":\"538172\",\"Description\":\"CHILLI LIGHTS\"}        |\n",
      "+------------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// to_json을 통해 structType을 JSON 문자열로 변경할 수 있음\n",
    "import org.apache.spark.sql.functions.to_json\n",
    "\n",
    "df.selectExpr(\"(InvoiceNo, Description) as myStruct\")\n",
    "    .select(to_json(col(\"myStruct\"))).show(2, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+--------------------------------------------------------------------------+\n",
      "|jsontostructs(newJSON)                   |newJSON                                                                   |\n",
      "+-----------------------------------------+--------------------------------------------------------------------------+\n",
      "|[538172, HAWAIIAN GRASS SKIRT ]          |{\"InvoiceNo\":\"538172\",\"Description\":\"HAWAIIAN GRASS SKIRT \"}              |\n",
      "|[538172, CHILLI LIGHTS]                  |{\"InvoiceNo\":\"538172\",\"Description\":\"CHILLI LIGHTS\"}                      |\n",
      "|[538172, \"RECORD FRAME 7\"\" SINGLE SIZE \"]|{\"InvoiceNo\":\"538172\",\"Description\":\"\\\"RECORD FRAME 7\\\"\\\" SINGLE SIZE \\\"\"}|\n",
      "|[538172, 3D DOG PICTURE PLAYING CARDS]   |{\"InvoiceNo\":\"538172\",\"Description\":\"3D DOG PICTURE PLAYING CARDS\"}       |\n",
      "|[538172, 60 CAKE CASES VINTAGE CHRISTMAS]|{\"InvoiceNo\":\"538172\",\"Description\":\"60 CAKE CASES VINTAGE CHRISTMAS\"}    |\n",
      "+-----------------------------------------+--------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "parseSchema = StructType(StructField(InvoiceNo,StringType,true), StructField(Description,StringType,true))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StructType(StructField(InvoiceNo,StringType,true), StructField(Description,StringType,true))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// to_json 함수에 JSON 데이터 소스와 동일한 형태의 딕셔너리를 파라미터로 사용할 수 있음\n",
    "// 그리고 from_json 함수를 사용해 JSON 문자열을 다시 객체로 변환할 수 있음\n",
    "import org.apache.spark.sql.functions.from_json\n",
    "import org.apache.spark.sql.types._\n",
    "\n",
    "val parseSchema = new StructType ( Array(\n",
    "    new StructField(\"InvoiceNo\", StringType, true), \n",
    "    new StructField(\"Description\", StringType, true)))\n",
    "\n",
    "df.selectExpr(\"(InvoiceNo, Description) as myStruct\")\n",
    "    .select(to_json(col(\"myStruct\")).alias(\"newJSON\"))\n",
    "    .select(from_json(col(\"newJSON\"), parseSchema), col(\"newJSON\")).show(5, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. 사용자 정의 함수\n",
    "\n",
    "스파크의 가장 강력한 기능중 하나로 사용자 정의 함수 (UDF)를 사용할 수 있다. <br>\n",
    "UDF는 파이썬, 스칼라, 외부 라이브러리를 사용해 사용자가 원하는 형태로 트랜스포메이션을 만들 수 있게 함. <br>\n",
    "<br>\n",
    "UDF는 하나 이상의 컬럼을 입력으로 받고, 반환할 수 있음. <br>\n",
    "레코드별로 데이터를 처리하는 함수이기 때문에 독특한 포맷이나 도메인에 특화된 언어를 사용하지 않음. <br>\n",
    "SparkSession, Context에서 사용할 수 있도록 임시 함수 형태로 등록함 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "udfExampleDF = [num: bigint]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "power3: (number: Double)Double\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val udfExampleDF = sc.range(5).toDF(\"num\")\n",
    "\n",
    "def power3(number:Double):Double = number * number * number\n",
    "power3(2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같이 함수를 만들고 테스트를 완료했으면, 실제 모든 워커 노드에서 생성된 함수를 사용할 수 있도록 스파크에 등록해야함 <br>\n",
    "스파크는 드라이버에서 함수를 직렬화하고 네트워크를 통해 모든 익스큐터 프로세스로 전달하며, 이과정은 언어와 관계 없이 발생함. <br>\n",
    "<br>\n",
    "함수를 개발한 언어에 따라 근본적으로 동작하는 방식이 달라짐. <br>\n",
    "스파크, 자바는 JVM환경에서만 사용할 수 있음. 따라서 스파크 내장 함수가 제공하는 코드 생성 기능의 장점을 활용할 수 없어 약간의 성능 저하가 발생함. <br>\n",
    "파이썬은 워커 노드에 파이썬 프로세스를 실행하고 파이썬이 이해할 수 있는 포맷으로 모든 데이터를 직렬화함. 그리고 파이썬 프로세스에 있는 모든 데이터의 로우마다 함수를 실행하고 마지막으로 JVM과 스파크에 처리 결과를 반환함. <br>\n",
    "<br>\n",
    "파이썬의 문제점으로 <br>\n",
    "1. 직렬화에 큰 부하가 발생함. (이는 스파크, 자바에서도 동일하게 발생)\n",
    "2. 스파크에서 파이썬 프로세스 실행 후 데이터를 전송하는데, 데이터가 전달되면 스파크에서 워커 메모리를 관리할 수 없음. 그러므로 JVM과 파이썬이 동일한 머신에서 메모리 경합을 하면 자원에 제약이 생겨 워커가 비정상적으로 종료될 가능성이 있음. \n",
    "3. 결론은 되도록이면 UDF는 자바나 스칼라로 작성하는 것이 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|UDF(num)|\n",
      "+--------+\n",
      "|0.0     |\n",
      "|1.0     |\n",
      "|8.0     |\n",
      "|27.0    |\n",
      "|64.0    |\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "power3udf = UserDefinedFunction(<function1>,DoubleType,Some(List(DoubleType)))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "UserDefinedFunction(<function1>,DoubleType,Some(List(DoubleType)))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.udf\n",
    "\n",
    "// 사용자 정의 함수는 Dataframe에서만 사용 가능. 문자열 표현식에서는 사용할 수 없다.\n",
    "// 하지만, 사용자 정의 함수를 스파크 SQL 함수로 등록하면 사용이 가능하다.\n",
    "val power3udf = udf(power3(_:Double):Double)\n",
    "udfExampleDF.select(power3udf(col(\"num\"))).show(5, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Hive UDF\n",
    "하이브 문법을 사용해 UDF/UDAF도 사용할 수 있다. <br>\n",
    "하지만 이렇게 하려면 SparkSession을 생성할 때, SparkSession.builder().enableHiveSupport()를 명시해 반드시 하이브 지원 기능을 활성화 해야함. <br>\n",
    "이 후 SQL로 UDF를 등록할 수 있다. <br>\n",
    "\n",
    "```\n",
    "-- SQL\n",
    "CREATE TEMPORARY FUNCTION myFunc AS 'com.organization.hive.udf.FunctionName'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
